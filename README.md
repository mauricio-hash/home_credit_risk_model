# Home Credit - Credit Risk Model Stability
O objetivo desta competi√ß√£o √© prever quais clientes s√£o mais propensos a n√£o pagarem seus empr√©stimos

### Relat√≥rio Executivo (Insights e efic√°cia)
Neste gr√°fico podemos avaliar a import√¢ncia de cada fator para a efici√™ncia do modelo, de modo que fatores mais importantes podem ser melhor registrados, ou terem uma valida√ß√£o melhor de modo que futuros modelos tenham uma melhor efic√°cia

![image](https://github.com/user-attachments/assets/e3ed2f09-76e5-4dbd-96e8-25136d6e7b77)

Fiz um outro modelo utilizando apenas dados de treino e vemos como caracter√≠sticas que n√£o estavam nos dados de teste podem fazer grande diferen√ßa no modelo, neste exemplo o fator district se mostrou ser um grande influenciador do modelo.

![image](https://github.com/user-attachments/assets/6e326859-d812-4df7-a7f3-3f00c6206a0b)


üìä M√©tricas no conjunto de treino:

AUC: 0.7589

Accuracy: 0.9671

F1-score: 0.0115

Precision: 1.0000

Recall: 0.0058

Conclus√µes a partir das m√©tricas:

1. Desequil√≠brio de classes √© forte
O F1-score muito baixo (0.0115), mesmo com precis√£o perfeita (1.0000), indica que o modelo quase nunca acerta casos positivos (classe minorit√°ria).

O Recall muito baixo (0.0058) significa que praticamente todos os casos positivos s√£o ignorados.

A acur√°cia alta (0.9671) pode ser enganosa nesse cen√°rio: provavelmente a classe negativa (maiorit√°ria) domina e o modelo acerta a maioria s√≥ por sempre prever "negativo".

2. O AUC (0.7589) √© razo√°vel
Isso sugere que o modelo consegue distinguir as classes at√© certo ponto, ou seja, o score de probabilidade tem alguma capacidade discriminativa.

AUC mede separa√ß√£o, n√£o decis√£o final. Isso mostra que talvez, ajustando o limiar de decis√£o, o modelo possa melhorar bastante, por padr√£o √© 0.5.









### Relat√≥rio T√©cnico (Deci√µes e futuras melhorias do modelo)

- Os dados utilizados s√£o provenientes de todas as bases com exce√ß√£o da base debitcard, pois n√£o encontrei informa√ß√µes relevantes para o modelo

- Utilizei apenas os case_ids que v√£o at√© o n√∫mero 100 mil, de modo que fosse poss√≠vel manipular as bases sem grandes problemas de uso de RAM

- Aplicar uma fun√ß√£o que converta cada categoria para o menor tipo poss√≠vel √© uma boa pr√°tica, no entanto, esta fun√ß√£o seria rodada ap√≥s o carregamento da base, n√£o fazendo tanta diferen√ßa para meu modelo

- Casos de um mesmo case_ids com diversas linhas referentes as mesmas caracter√≠sticas foram removidos, baseado na regra keep = 'first', isto √© mant√©m-se o primeiro.

- Para uma melhor performance do modelo, utilizar agrega√ß√µes de modo que n√£o se perca tanta informa√ß√£o. Em caso de dados num√©ricos pode-se usar: min, max, m√©dia, mediana, first, last.
  E em caso de dados categ√≥ricos usar: first, last, ou modo

- Remover categorias com poucas informa√ß√µes, ou seja algo em torno de 90% a 95% de dados faltantes, pode ser uma boa pr√°tica para aumentar a simplicidade e efici√™ncia do modelo.

- Verifiquei que a base de treino e teste tinhas colunas desiguais, isto √©, que existia em uma e n√£o na outra, ent√£o removi-as de modo a ter dois datasets com as mesma colunas de caracter√≠sticas para utilizar o modelo.

- Ao fim utilizei random_search para otimizar meus pa√¢metros para o modelo Light GBM, em virtude de sua velocidade, utilizar outros modelos pode ser interessante.

- O modelo usado foi o Light GBM, em virtude dos seus grandes resultados com problemas de classifica√ß√£o, utilizar XGBoost ou CatBoost serias op√ß√µes tamb√©m com bom prospecto neqste tipo de problema.




![image](https://github.com/user-attachments/assets/e0662042-1f06-4fd5-a450-f67711534f1d)

